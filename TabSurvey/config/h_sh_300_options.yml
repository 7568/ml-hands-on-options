# General parameters
dataset: H_sh_300_options
model_name: SAINT # LinearModel, KNN, SVM, DecisionTree, RandomForest, XGBoost, CatBoost, LightGBM, ModelTree
# MLP, TabNet, VIME, TabTransformer, RLN, DNFNet, STG, NAM, DeepFM, SAINT
objective: binary # Don't change
# optimize_hyperparameters: True

use_gpu: True
# use one GPU parameters
gpu_index: 7
# use GPU data_parallel parameters
gpu_ids: [ 0, 1 ]
data_parallel: False



# Optuna parameters - https://optuna.org/
n_trials: 2
direction: maximize

# Cross validation parameters
num_splits: 5
shuffle: True
seed: 221 # Don't change

# Preprocessing parameters
scale: False
target_encode: False
one_hot_encode: False

# Training parameters
batch_size: 128
val_batch_size: 256
early_stopping_rounds: 100
epochs: 500
logging_period: 10



# About the data
num_classes: 1  # for classification
num_features: 185
cat_idx: [ 0, 28, 50, 73, 87, 110, 124, 147, 161, 184 ]
# cat_dims: will be automatically set.
#cat_dims: [ 2, 2, 2, 2, 2, 2, 2, 2, 2, 2 ]